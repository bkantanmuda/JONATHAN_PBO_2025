{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyVshACd6E6y26tTjaqNGl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkantanmuda/JONATHAN_PBO_2025/blob/main/Pratikum_4_visi_Komputer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEKNIK ANALISIS POSE & GEOMETRI TUBUH PADA GAMBAR\n",
        "## Jonathan Edward Sinaga\n",
        "## 4.33.24.0.14\n",
        "## TI-2A"
      ],
      "metadata": {
        "id": "3LW4g1C24m_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D1 - inisialisasi kamera dengan akusisi citra"
      ],
      "metadata": {
        "id": "i0CPFJBx3yab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFaZSTrt3m2-"
      },
      "outputs": [],
      "source": [
        "import cv2, time\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened ():\n",
        "    raise RuntimeError(\"kamera tidak bisa dibuka, coba index 1/2.\")\n",
        "\n",
        "frames, t0 = 0, time.time()\n",
        "while True:\n",
        "    ok, frame = cap.read()\n",
        "    if not ok: break\n",
        "    frames += 1\n",
        "    if time.time() - t0 >= 1.0:\n",
        "        cv2.setWindowTitle(\"Preview\", f\"Preview (FPS ~ {frames})\")\n",
        "        frames, t0 = 0, time.time()\n",
        "    cv2.imshow(\"Preview\", frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord ('q') : break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D2 - deteksi pose dan analisis sudut tubuh"
      ],
      "metadata": {
        "id": "MPmac4Zj37Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, numpy as np\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
        "\n",
        "detector = PoseDetector(\n",
        "    staticMode=False,\n",
        "    modelComplexity=1,\n",
        "    enableSegmentation=False,\n",
        "    detectionCon=0.5,\n",
        "    trackCon=0.5\n",
        ")\n",
        "\n",
        "while True:\n",
        "    ok, img = cap.read()\n",
        "    if not ok:\n",
        "        break\n",
        "\n",
        "    img = detector.findPose(img)\n",
        "    lmlist, bboxInfo = detector.findPosition(img, draw=True, bboxWithHands=False)\n",
        "\n",
        "    if bboxInfo and lmlist:\n",
        "        center = bboxInfo[\"center\"]\n",
        "        cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\n",
        "\n",
        "        length, img, info = detector.findDistance(\n",
        "            lmlist[11][0:2],\n",
        "            lmlist[15][0:2],\n",
        "            img=img,\n",
        "            scale=10\n",
        "        )\n",
        "\n",
        "        angle, img = detector.findAngle(\n",
        "            lmlist[11][0:2],\n",
        "            lmlist[13][0:2],\n",
        "            lmlist[15][0:2],\n",
        "            img=img\n",
        "        )\n",
        "\n",
        "    cv2.imshow(\"Pose\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "-i371-Gz4UFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D3 - deteksi wajah dan analisis kedipan wajah"
      ],
      "metadata": {
        "id": "K19oG74X4AKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, numpy as np\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "\n",
        "# indeks mata kiri (contoh): vertikal (159, 145), horizontal (33, 133)\n",
        "L_TOP, L_BOTTOM, L_LEFT, L_RIGHT = 159, 145, 33, 133\n",
        "\n",
        "def dist(p1, p2): return np.linalg.norm(np.array(p1) - np.array(p2))\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"kamera tidak bisa dibuka.\")\n",
        "\n",
        "# inisialisasi objek FaceMeshDetector\n",
        "# staticMode: jika true, deteksi hanya terjadi sekali, jika false, satiap frame\n",
        "# maxFaces: Jumlah maksimum wajah yang dideteksi\n",
        "# minDetectionCon: ambang kepercayaan deteksi minimum\n",
        "# minTrackCon: ambang kepercayaan pelacakan minimum\n",
        "\n",
        "detector = FaceMeshDetector(staticMode=False, maxFaces=2, minDetectionCon=0.5, minTrackCon=0.5)\n",
        "\n",
        "# variable untuk menghitung kedipan sederhana\n",
        "blink_count = 0\n",
        "closed_frames = 0\n",
        "CLOSED_FRAMES_THRESHOLD = 3 #jumlah frame berturut-turut untuk dianggap kedipan\n",
        "EYE_AR_THRESHOLD = 0.20 # ambang Eye Aspect Ratio (EAR) untuk menilai mata tertutup\n",
        "is_closed = False\n",
        "\n",
        "while True:\n",
        "    ok, img = cap.read()\n",
        "    if not ok: break\n",
        "    img, faces = detector.findFaceMesh(img, draw=True)\n",
        "    if faces:\n",
        "        face = faces[0] # list of 468 (x,y)\n",
        "        v = dist (face[L_TOP], face[L_BOTTOM])\n",
        "        h = dist (face[L_LEFT], face[L_RIGHT])\n",
        "        ear = v / (h + 1e-8)\n",
        "        cv2.putText(img,f\"EAR (L): {ear:.3f}\", (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2)\n",
        "        if ear < EYE_AR_THRESHOLD:\n",
        "            closed_frames += 1\n",
        "            if closed_frames >= CLOSED_FRAMES_THRESHOLD and not is_closed:\n",
        "                blink_count += 1\n",
        "                is_closed = True\n",
        "        else:\n",
        "            closed_frames = 0\n",
        "            is_closed = False\n",
        "\n",
        "        cv2.putText(img, f\"Blink: {blink_count}\", (20,70), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
        "\n",
        "    cv2.imshow(\"FaceMesh + EAR\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord ('q'): break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "lfijANg84btF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D4 - deteksi tangan dan perhitunfan jumlah jari"
      ],
      "metadata": {
        "id": "myjJolck4Dyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
        "\n",
        "detector = HandDetector(staticMode=False, maxHands=1,  modelComplexity=1 ,detectionCon=0.5, minTrackCon=0.5)\n",
        "\n",
        "while True:\n",
        "    ok, img = cap.read()\n",
        "    if not ok: break\n",
        "    hands, img = detector.findHands(img, draw=True ,flipType=False)\n",
        "    if hands:\n",
        "        hand = hands[0]\n",
        "        fingers = detector.fingersUp(hand)\n",
        "        count = sum(fingers)\n",
        "        cv2.putText(img, f\"Fingers: {count} {fingers}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow(\"Hands + Fingers\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "FAsLbcDy4dU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D5 - pengenalan gestur tangan (hand gesture recognotion)"
      ],
      "metadata": {
        "id": "L4-zj0rj4H0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "\n",
        "def dist(a, b):\n",
        "    return np.linalg.norm(np.array(a) - np.array(b))\n",
        "\n",
        "def classify_gesture(hand):\n",
        "    # hand[\"lmList\"] berisi 21 titik (x,y,z) dalam piksel saat flipType=True\n",
        "    lm = hand[\"lmList\"]\n",
        "    wrist = np.array(lm[0][:2])\n",
        "    thumb_tip = np.array(lm[4][:2])\n",
        "    index_tip = np.array(lm[8][:2])\n",
        "    middle_tip = np.array(lm[12][:2])\n",
        "    ring_tip = np.array(lm[16][:2])\n",
        "    pinky_tip = np.array(lm[20][:2])\n",
        "\n",
        "    # Heuristik jarak relatif\n",
        "    r_mean = np.mean([\n",
        "        dist(index_tip, wrist),\n",
        "        dist(middle_tip, wrist),\n",
        "        dist(ring_tip, wrist),\n",
        "        dist(pinky_tip, wrist),\n",
        "        dist(thumb_tip, wrist)\n",
        "    ])\n",
        "\n",
        "    # Aturan:\n",
        "    if dist(thumb_tip, index_tip) < 35:\n",
        "        return \"OK\"\n",
        "\n",
        "    # Thumbs up: ibu jari tinggi (y kecil), dan jauh dari wrist\n",
        "    if (thumb_tip[1] < wrist[1] - 40) and (dist(thumb_tip, wrist) > 0.8 * dist(index_tip, wrist)):\n",
        "        return \"THUMBS_UP\"\n",
        "\n",
        "    if r_mean < 120:\n",
        "        return \"ROCK\"\n",
        "\n",
        "    if r_mean > 200:\n",
        "        return \"PAPER\"\n",
        "\n",
        "    if dist(index_tip, wrist) > 180 and dist(middle_tip, wrist) > 180 and \\\n",
        "       dist(ring_tip, wrist) < 160 and dist(pinky_tip, wrist) < 160:\n",
        "        return \"SCISSORS\"\n",
        "\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
        "\n",
        "detector = HandDetector(\n",
        "    staticMode=False,\n",
        "    maxHands=1,\n",
        "    modelComplexity=1,\n",
        "    detectionCon=0.5,\n",
        "    minTrackCon=0.5\n",
        ")\n",
        "\n",
        "while True:\n",
        "    ok, img = cap.read()\n",
        "    if not ok:\n",
        "        break\n",
        "\n",
        "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
        "\n",
        "    if hands:\n",
        "        label = classify_gesture(hands[0])\n",
        "        cv2.putText(\n",
        "            img,\n",
        "            f\"Gesture: {label}\",\n",
        "            (20, 40),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.9,\n",
        "            (0, 255, 255),\n",
        "            2\n",
        "        )\n",
        "\n",
        "    cv2.imshow(\"Hand Gestures (cvzone)\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UXtmDcj44iNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D6 - analisis gerakan tubuh dan perhitungan aktivitas"
      ],
      "metadata": {
        "id": "kkPJwadV4PD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "\n",
        "MODE = \"squat\"   # tekan 'm' untuk toggle ke \"pushup\"\n",
        "KNEE_DOWN, KNEE_UP = 80, 160     # ambang squat (deg)\n",
        "DOWN_R, UP_R = 0.85, 1.00        # ambang push-up (rasio)\n",
        "SAMPLE_OK = 4                    # minimal frame konsisten sebelum ganti state\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
        "\n",
        "detector = PoseDetector(\n",
        "    staticMode=False,\n",
        "    modelComplexity=1,\n",
        "    enableSegmentation=False,\n",
        "    detectionCon=0.5,\n",
        "    trackCon=0.5\n",
        ")\n",
        "\n",
        "count, state = 0, \"up\"\n",
        "debounce = deque(maxlen=6)\n",
        "\n",
        "def ratio_pushup(lm):\n",
        "    # gunakan kiri: 11=shoulderL, 15=wristL, 23=hipL\n",
        "    sh = np.array(lm[11][1:3])\n",
        "    wr = np.array(lm[15][1:3])\n",
        "    hp = np.array(lm[23][1:3])\n",
        "    return np.linalg.norm(sh - wr) / (np.linalg.norm(sh - hp) + 1e-8)\n",
        "\n",
        "while True:\n",
        "    ok, img = cap.read()\n",
        "    if not ok:\n",
        "        break\n",
        "\n",
        "    img = detector.findPose(img, draw=True)\n",
        "    lmList, _ = detector.findPosition(img, draw=False)  # [(id,x,y,z,vis), ...]\n",
        "    flag = None\n",
        "\n",
        "    if lmList:\n",
        "        if MODE == \"squat\":\n",
        "            # rata-rata sudut lutut kiri & kanan\n",
        "            # angL, _ = detector.findAngle(img, 23, 25, 27, draw=False)\n",
        "            # angR, _ = detector.findAngle(img, 24, 26, 28, draw=False)\n",
        "\n",
        "            angL, img = detector.findAngle(\n",
        "                lmList[23][0:2],\n",
        "                lmList[25][0:2],\n",
        "                lmList[27][0:2],\n",
        "                img=img,\n",
        "                color=(0, 0, 255),\n",
        "                scale=10\n",
        "            )\n",
        "\n",
        "            angR, img = detector.findAngle(\n",
        "                lmList[24][0:2],\n",
        "                lmList[26][0:2],\n",
        "                lmList[28][0:2],\n",
        "                img=img,\n",
        "                color=(0, 255, 0),\n",
        "                scale=10\n",
        "            )\n",
        "\n",
        "            ang = (angL + angR) / 2.0\n",
        "            if ang < KNEE_DOWN:\n",
        "                flag = \"down\"\n",
        "            elif ang > KNEE_UP:\n",
        "                flag = \"up\"\n",
        "\n",
        "            cv2.putText(\n",
        "                img,\n",
        "                f\"Knee: {ang:5.1f}\",\n",
        "                (20, 70),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.8,\n",
        "                (0, 255, 0),\n",
        "                2\n",
        "            )\n",
        "        else:\n",
        "            # push-up: rasio (shoulder–wrist)/(shoulder–hip)\n",
        "            r = ratio_pushup(lmList)\n",
        "            if r < DOWN_R:\n",
        "                flag = \"down\"\n",
        "            elif r > UP_R:\n",
        "                flag = \"up\"\n",
        "\n",
        "            cv2.putText(\n",
        "                img,\n",
        "                f\"Ratio: {r:4.2f}\",\n",
        "                (20, 70),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.8,\n",
        "                (0, 255, 255),\n",
        "                2\n",
        "            )\n",
        "\n",
        "        debounce.append(flag)\n",
        "        if debounce.count(\"down\") >= SAMPLE_OK and state == \"up\":\n",
        "            state = \"down\"\n",
        "        if debounce.count(\"up\") >= SAMPLE_OK and state == \"down\":\n",
        "            state = \"up\"\n",
        "            count += 1\n",
        "\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        f\"Mode: {MODE.upper()}  Count: {count}\",\n",
        "        (20, 40),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.9,\n",
        "        (255, 255, 255),\n",
        "        2\n",
        "    )\n",
        "\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        f\"State: {state}\",\n",
        "        (20, 100),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.8,\n",
        "        (255, 255, 255),\n",
        "        2\n",
        "    )\n",
        "\n",
        "    cv2.imshow(\"Pose Counter\", img)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "    if key == ord('m'):\n",
        "        MODE = \"pushup\" if MODE == \"squat\" else \"squat\"\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "nxE0hrQW4k9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}